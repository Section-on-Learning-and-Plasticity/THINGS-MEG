{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures for within-participant regression analysis \n",
    "1) Results Figure 2 (average timeseries, snapshot roseplots (removed in revision), snapshot topoplots, example timeseries)\n",
    "2) Supplementary Figure S1 (timeseries for all dimensions)\n",
    "3) One example timeseries\n",
    "4) Dynamic roseplot\n",
    "5) Dynamic topoplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: linateichmann\n",
    "Email: lina.teichmann@nih.gov\n",
    "\n",
    "    Created on 2023-03-30 12:40:16\n",
    "    Modified on 2023-03-30 12:40:16\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import mne, os\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# bids_dir = '/System/Volumes/Data/misc/data16/teichmanna2/2020_MEG_things/THINGS_biowulf/THINGS-MEG-bids/'\n",
    "bids_dir = '/Volumes/THINGS-MEG/THINGS-MEG-bids'\n",
    "res_folder = f'{bids_dir}/derivatives/meg_paper/output/regression'\n",
    "font = 'Arial'\n",
    "text_size = 12\n",
    "text_size_big = 16\n",
    "text_size_small = 6\n",
    "\n",
    "plt.rcParams['font.size'] = text_size\n",
    "plt.rcParams['font.family'] = font\n",
    "\n",
    "colours = pd.read_csv(f'{bids_dir}/sourcedata/meg_paper/colors66.txt',header=None)\n",
    "labels = pd.read_csv(f'{bids_dir}/sourcedata/meg_paper/labels_super_short.txt',header=None)\n",
    "\n",
    "\n",
    "# load data\n",
    "def load_epochs(bids_dir,participant,behav):\n",
    "    epochs = mne.read_epochs(f'{bids_dir}/derivatives/preprocessed/preprocessed_P{participant}-epo.fif',preload=False)\n",
    "    # THINGS-category number & image number start at 1 (matlab based) so subtracting 1 to use for indexing\n",
    "    epochs.metadata['things_image_nr'] = epochs.metadata['things_image_nr']-1\n",
    "    epochs.metadata['things_category_nr'] = epochs.metadata['things_category_nr']-1\n",
    "    # adding dimensional weights to metadata\n",
    "    epochs.metadata[['dim'+ str(d+1) for d in range(66)]] = np.nan\n",
    "    for i in range(len(epochs.metadata)):\n",
    "        if not np.isnan(epochs.metadata.loc[i,'things_image_nr']):\n",
    "            epochs.metadata.loc[i,['dim'+ str(d+1) for d in range(66)]] = behav[int(epochs.metadata.loc[i,'things_image_nr']),:]\n",
    "    return epochs\n",
    "\n",
    "\n",
    "behav = np.loadtxt(f'{bids_dir}/sourcedata/meg_paper/predictions_66d_elastic_clip-ViT-B-32_visual_THINGS.txt')\n",
    "epochs = load_epochs(bids_dir,1,behav)\n",
    "\n",
    "epochs_exp = epochs[(epochs.metadata['trial_type']=='exp')]   \n",
    "epochs_exp.metadata.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "# load results\n",
    "all_dat_dims=[]\n",
    "all_dat_sens=[]\n",
    "\n",
    "for p in range(1,5):\n",
    "    corr_ridge= []\n",
    "    for cv in range(1,13):\n",
    "        print(f'loading results from participant {p} cv {cv}')\n",
    "        y_pred = np.load(f'{res_folder}/P{p}_ridge-reg_within_predict-dims_ypred_cv{cv}.npy')\n",
    "        y_true = np.load(f'{res_folder}/P{p}_ridge-reg_within_predict-dims_ytrue_cv{cv}.npy')\n",
    "        corr_t = []\n",
    "        for t in range(y_pred.shape[0]):\n",
    "            corr_t.append([np.corrcoef(y_pred[t,:,d],y_true[:,d])[0,1] for d in range(66)])\n",
    "        corr_ridge.append(np.array(corr_t))\n",
    "        \n",
    "    all_dat_dims.append(np.mean(corr_ridge,axis=0))\n",
    "    all_dat_sens.append(pd.read_csv(f'{res_folder}/P{p}_linreg_within_predict-sens.csv',index_col=0))\n",
    "\n",
    "# change data order based on peak amplitude\n",
    "avg_dim_data = np.mean(all_dat_dims,axis=0)\n",
    "sorted_idx = np.flipud(np.argsort(np.max(avg_dim_data,axis=0)))\n",
    "\n",
    "avg_dim_data_ranked = avg_dim_data[:,sorted_idx]\n",
    "dim_data_ranked = np.array(all_dat_dims)[:,:,sorted_idx]\n",
    "colours_ranked = colours.to_numpy()[sorted_idx,:]\n",
    "labels_ranked = labels.loc[sorted_idx,:]\n",
    "labels_ranked.reset_index(inplace=True,drop=True)\n",
    "\n",
    "filter_col = [col for col in epochs_exp.metadata.columns if col.startswith('dim')] \n",
    "weights_sorted_dims = epochs_exp.metadata.loc[:,filter_col].to_numpy()[:,sorted_idx]\n",
    "\n",
    "\n",
    "labels_ranked_list = labels_ranked.loc[:,0].to_list()\n",
    "labels_ranked_list = [item.replace('/', '') for item in labels_ranked_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load permutation results and check for significance at an individual level\n",
    "significance_mat,significance_mat_avg = [],[]\n",
    "for participant in range(4):\n",
    "    # load permutations\n",
    "    corr_ridge_perm_all = np.load(f'{res_folder}/P{participant+1}_ridge-reg_within_predict-dims_permutations.npy') \n",
    "    # average over cross-validation splits\n",
    "    corr_ridge_perm_avgcv = np.mean(corr_ridge_perm_all,axis=0)\n",
    "    # get 95%ile for each timepoint and each dimension null-distribution\n",
    "    thresholds = np.array([[np.percentile(corr_ridge_perm_avgcv[:,t,d],99) for t in range(281)] for d in range(66)])\n",
    "    # threshold defined as the max 95%ile across time and dimensions\n",
    "    threshold = np.max(thresholds)\n",
    "\n",
    "    significance_mat.append(np.array(all_dat_dims)[participant,:,:]>threshold)\n",
    "    significance_mat_avg.append(np.mean(np.array(all_dat_dims)[participant,:,:],axis=1)>threshold)\n",
    "\n",
    "\n",
    "# generate one matrix that is participants x dimensions x time that tells us when stuff is significant    \n",
    "significance_mat = np.array(significance_mat)\n",
    "significance_mat_avg = np.array(significance_mat_avg)\n",
    "significance_mat_rank = significance_mat[:,:,sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE RESULTS FIGURE\n",
    "dim_ranks = [int(i) for i in np.round(np.linspace(0,65,6))]\n",
    "\n",
    "plt.close('all')\n",
    "axd = plt.figure(constrained_layout=True, figsize=(8.25, 11.75)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    .AAAAAA\n",
    "    .AAAAAA\n",
    "    .BBBCCC\n",
    "    .BBBCCC\n",
    "    .DDDEEE\n",
    "    .DDDEEE\n",
    "    .FFFGGG\n",
    "    .FFFGGG\n",
    "    .......\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "fig = plt.gcf()\n",
    "#### make figure\n",
    "axd['A'].plot(epochs.times*1000, epochs.times*0, 'grey', lw=1, linestyle='--')\n",
    "\n",
    "# plot individual data and mean \n",
    "for p in range(4):\n",
    "    axd['A'].plot(epochs.times*1000,all_dat_dims[p].mean(axis=1),'k',alpha=0.3,lw=1)\n",
    "    sig_tp = (epochs.times*1000)[significance_mat_avg[p,:]]\n",
    "    axd['A'].plot(sig_tp,np.repeat(-.02-(p*1/100),len(sig_tp==1)),'k.',alpha=0.3,markersize=3)\n",
    "    axd['A'].text(1310,-.025-(p*1/100),f'S0{p+1}: p<0.01',c='k',fontsize=5.8,ha='left')\n",
    "    \n",
    "    \n",
    "axd['A'].plot(epochs.times*1000,np.mean(np.mean(all_dat_dims,axis=0),axis=1),'k',alpha=1,lw=3)\n",
    "\n",
    "\n",
    "axd['A'].set_xlim([epochs.times[0]*1000,epochs.times[-1]*1000])\n",
    "axd['A'].set_ylim([-0.07,0.15])\n",
    "axd['A'].set_xlabel('time (ms)')\n",
    "axd['A'].set_ylabel('Correlation:\\n true vs predicted label')\n",
    "\n",
    "axd['A'].spines['top'].set_visible(False)\n",
    "axd['A'].spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "ts = np.arange(-100,1400,200)\n",
    "axd['A'].set_xticks(ts)\n",
    "\n",
    "# add topoplots\n",
    "for t in ts:\n",
    "    t_idx = np.where(epochs.times*1000 == t)[0][0]\n",
    "    height_topo = .2\n",
    "    width_topo = 150\n",
    "    axin2 = axd['A'].inset_axes([t-width_topo/2,-0.32, width_topo,height_topo], transform= axd['A'].transData)\n",
    "\n",
    "    tix = np.where(t==epochs.times*1000)[0][0]\n",
    "    topo,cm=mne.viz.plot_topomap(np.mean(all_dat_sens,axis=0)[tix,:], epochs.info,vlim=[0,0.2],cmap='RdPu',axes=axin2,\n",
    "                                    sensors=False,contours=False)\n",
    "\n",
    "    if t == ts[0]:\n",
    "        cbar_ax = fig.add_axes([0.04,0.72,0.008,0.05])\n",
    "        clb = fig.colorbar(topo, cax=cbar_ax)\n",
    "\n",
    "    # add arrows\n",
    "    con = ConnectionPatch(xyA=(t,axd['A'].get_ylim()[0]), xyB=(0,axin2.get_ylim()[1]), \n",
    "                            coordsA=\"data\", coordsB=\"data\",\n",
    "                            axesA=axd['A'], axesB=axin2, color=\"black\", linestyle='--',arrowstyle=\"-|>\")\n",
    "    axd['A'].add_artist(con)\n",
    "\n",
    "    if tix!=0:\n",
    "        ypoint = np.max([all_dat_dims[p].mean(axis=1)[tix] for p in range(4)])+0.01\n",
    "    else:\n",
    "        ypoint = axd['A'].get_ylim()[1]+0.01\n",
    "\n",
    "    plt.setp(axd['A'].get_xticklabels(), backgroundcolor=\"white\")\n",
    "\n",
    "\n",
    "# add individual timeseries\n",
    "for rank,ax in zip(dim_ranks,[axd['B'],axd['C'],axd['D'],axd['E'],axd['F'],axd['G']]):\n",
    "    ax.plot(epochs.times*1000, epochs.times*0, 'grey', lw=1, linestyle='--')\n",
    "    \n",
    "    for p in range(4):\n",
    "        ax.plot(epochs.times*1000,dim_data_ranked[p,:,rank],c=colours_ranked[rank,:],alpha=0.3,lw=1)\n",
    "        sig_tp = (epochs.times*1000)[significance_mat_rank[p,:,rank]]\n",
    "        ax.plot(sig_tp,np.repeat(-.02-(p*1/50),len(sig_tp==1)),'k.',mfc=colours_ranked[rank,:],mec=colours_ranked[rank,:],alpha=0.3,markersize=3)\n",
    "        # ax.text(1310,-.025-(p*1/50),f'S0{p+1}: p<0.01',c='k',fontsize=4.5,ha='left')\n",
    "        \n",
    "    ax.plot(epochs.times*1000,avg_dim_data_ranked[:,rank],c=colours_ranked[rank,:],lw=2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_ylim([-0.09,0.5])\n",
    "    ax.set_ylabel('Correlation')\n",
    "    ax.set_xlabel('time (ms)')\n",
    "    ax.set_title(' ')\n",
    "    ax.text(700,0.5,f'{labels_ranked.loc[rank,0]} ({sorted_idx[rank]+1})',c='k',fontsize=text_size,ha='center')\n",
    "\n",
    "    ax.set_xlim([epochs.times[0]*1000,epochs.times[-1]*1000])\n",
    "\n",
    "\n",
    "\n",
    "# add example images\n",
    "labels_ranked_list\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "example_im_path = f'{bids_dir}/sourcedata/meg_paper/example_images/'\n",
    "\n",
    "for ii,x in enumerate(np.arange(0.1,0.9,0.15)):\n",
    "    for i,dim in enumerate(dim_ranks):\n",
    "        image = plt.imread(f'{example_im_path}/{labels_ranked_list[dim]}/{ii}.jpg')\n",
    "        imagebox = OffsetImage(image, zoom=0.08)\n",
    "        ab = AnnotationBbox(imagebox, (x, .73), frameon=False, xycoords='axes fraction', boxcoords=\"offset points\", pad=0)\n",
    "        axd[chr(ord('B')+i)].add_artist(ab)\n",
    "\n",
    "# labels\n",
    "axd['B'].text(-400,0.3,' ',fontsize=text_size_big*3)\n",
    "fig.text(0.01,0.97,'A',fontsize=text_size_big*2)\n",
    "fig.text(0.01,0.67,'B',fontsize=text_size_big*2)\n",
    "\n",
    "fig.savefig(f'{bids_dir}/derivatives/meg_paper/figures/Figure2.pdf')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplementary figure showing all dimension timecourses\n",
    "plt.close('all')\n",
    "fig,axs = plt.subplots(figsize=(8.25, 11.75),num=2,ncols=6,nrows=11,sharex=True,sharey=True)\n",
    "\n",
    "axs=axs.flatten()\n",
    "\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.plot(epochs.times*1000,epochs.times*0,'grey',linestyle='--')\n",
    "    for p in range(4):\n",
    "        ax.plot(epochs.times*1000,np.array(dim_data_ranked)[p,:,i],c=colours_ranked[i,:],alpha=0.3,lw=1)\n",
    "        sig_tp = (epochs.times*1000)[significance_mat_rank[p,:,i]]\n",
    "        ax.plot(sig_tp,np.repeat(-.02-(p*1/50),len(sig_tp==1)),'k.',mfc=colours_ranked[i,:],mec=colours_ranked[i,:],alpha=0.3,markersize=.8)\n",
    "\n",
    "    ax.plot(epochs.times*1000,avg_dim_data_ranked[:,i],c=colours_ranked[i,:],lw=2)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_ylim([-0.11,0.3])\n",
    "\n",
    "    ax.set_title(f'{labels_ranked.loc[i,0]}\\n({sorted_idx[i]+1})',c='k',fontsize=text_size_small)\n",
    "    ax.set_xlim([epochs.times[0]*1000,epochs.times[-1]*1000])\n",
    "\n",
    "\n",
    "fig.supylabel('Correlation: true vs predicted label')\n",
    "fig.supxlabel('time (ms)')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'{bids_dir}/derivatives/meg_paper/figures/Supplementary_within.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure for example timeseries\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "\n",
    "i = 7\n",
    "ax.plot(epochs.times*1000,epochs.times*0,'grey',linestyle='--')\n",
    "ax.plot(epochs.times*1000,avg_dim_data_ranked[:,i],c=colours_ranked[i,:],alpha=1,lw=2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_ylim([-0.05,0.3])\n",
    "ax.set_title('Dimension 11: ' + str(labels_ranked.loc[i,0]),c=colours_ranked[i,:],fontsize=text_size)\n",
    "ax.set_xlim([epochs.times[0]*1000,epochs.times[-1]*1000])\n",
    "\n",
    "\n",
    "ax.set_ylabel('Correlation:\\ntrue vs predicted label')\n",
    "ax.set_xlabel('time (ms)')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'{bids_dir}/sourcedata/meg_paper/example_timeseries.png', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roseplot animation\n",
    "plt.close('all')\n",
    "n_dims = 66\n",
    "theta = np.linspace(0.0, 2 * np.pi, n_dims, endpoint=False)\n",
    "n_dims = np.array(dim_data_ranked).shape[2]\n",
    "width = np.pi/n_dims\n",
    "\n",
    "fig= plt.figure(num=1, figsize=(10,7))\n",
    "ax = plt.subplot(projection='polar')\n",
    "title = ax.text(0.5,0.85, \"\", bbox={'facecolor':'w', 'alpha':0.5, 'pad':5},\n",
    "                transform=ax.transAxes, ha=\"center\")\n",
    "\n",
    "def init(t=0):\n",
    "    radii = np.mean(dim_data_ranked,axis=0)[t,:]\n",
    "    bars = ax.bar(theta, radii, width=width, bottom=0, color=colours_ranked, alpha=1)\n",
    "    ax.set_ylim(0,0.3)\n",
    "    ax.set_rlabel_position(315)\n",
    "    title.set_text(str(epochs.times[t]*1000) +' ms')\n",
    "    return bars\n",
    "\n",
    "def update(t):\n",
    "    ax.cla()\n",
    "    ax.set_ylim(0,0.3)\n",
    "    ax.text(np.radians(ax.get_rlabel_position())-.1,ax.get_rmax()/2,'Correlation',\n",
    "        rotation=ax.get_rlabel_position(),ha='center',va='center')\n",
    "    ax.axes.set_xticks([np.radians(315)])\n",
    "    ax.axes.set_xticklabels('')\n",
    "    ax.yaxis.grid(True,color='k',linestyle=':',alpha=0.5)\n",
    "\n",
    "\n",
    "    radii = np.mean(dim_data_ranked,axis=0)[t,:]\n",
    "    gets_a_label = np.where(radii>0.1)[0]\n",
    "\n",
    "    bars = ax.bar(theta, radii, width=width, bottom=0, color=colours_ranked, alpha=1)\n",
    "\n",
    "    if np.any(gets_a_label):\n",
    "        for dim in gets_a_label:\n",
    "            rotations = np.rad2deg(theta[dim])\n",
    "            if rotations>90 and rotations<270:\n",
    "                rotations = rotations-180\n",
    "                label = labels_ranked.loc[dim,0] +' ' \n",
    "                ha = 'right'\n",
    "            else:\n",
    "                ha='left'\n",
    "                label = ' ' + labels_ranked.loc[dim,0]\n",
    "            lab = plt.text(theta[dim],radii[dim],label, ha=ha, va='center', rotation=rotations, rotation_mode=\"anchor\",fontsize=8) \n",
    "    \n",
    "    plt.title(str(epochs.times[t]*1000) +' ms')\n",
    "    title.set_text(str(int(epochs.times[t]*1000)) +' ms')\n",
    "    \n",
    "    return bars\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(epochs.times)-80,init_func=init,blit=False,cache_frame_data=False,repeat=False)\n",
    "writer = animation.PillowWriter(fps=3)\n",
    "\n",
    "ani.save(f'{bids_dir}/derivatives/meg_paper/figures/roseplot_short.gif',writer=writer, dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topoplot animation\n",
    "plt.close('all')\n",
    "fig,ax = plt.subplots(num=1, figsize=(5,5))\n",
    "title = ax.text(0.5,0.85, \"\", bbox={'facecolor':'w', 'alpha':0.5, 'pad':5},\n",
    "                transform=ax.transAxes, ha=\"center\")\n",
    "\n",
    "def init(t=0):\n",
    "    topo,cm = mne.viz.plot_topomap(np.mean(all_dat_sens,axis=0)[t,:], epochs.info,vlim=[0,0.2],cmap='RdPu',axes=ax,\n",
    "                                        sensors=True,contours=False)\n",
    "    cbar = fig.colorbar(topo,fraction=0.03, pad=0.04)\n",
    "    cbar.set_label('Correlation')\n",
    "    fig.tight_layout()\n",
    "    title.set_text(str(epochs.times[t]*1000) +' ms')\n",
    "    return topo\n",
    "\n",
    "def update(t):\n",
    "    ax.cla()\n",
    "    topo,cm = mne.viz.plot_topomap(np.mean(all_dat_sens,axis=0)[t,:], epochs.info,vlim=[0,0.2],cmap='RdPu',axes=ax,\n",
    "                                        sensors=True,contours=False)\n",
    "    fig.tight_layout()\n",
    "    plt.title(str(int(epochs.times[t]*1000)) +' ms')\n",
    "    return topo\n",
    "\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(epochs.times)-80,init_func=init,blit=False,cache_frame_data=False,repeat=False)\n",
    "\n",
    "writer = animation.PillowWriter(fps=3)\n",
    "\n",
    "ani.save(f'{bids_dir}/derivatives/meg_paper/figures/topoplot_short.gif',writer=writer, dpi=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load cross-participant results\n",
    "all_dat_dims_cross = []\n",
    "for test_participant in range(1,5):\n",
    "    train_participants = [i for i in np.arange(1,5) if i !=test_participant]\n",
    "    res_ppt  =[]\n",
    "    for train_participant in train_participants:\n",
    "        for cv in range(1,13):\n",
    "            res_ppt.append(pd.read_csv(f'{res_folder}/Ridge-reg_cross_trainP{train_participant}_testP{test_participant}_cv{cv}.csv',index_col=0).to_numpy())\n",
    "\n",
    "    all_dat_dims_cross.append(np.mean(res_ppt,axis=0))\n",
    "all_dat_dims_cross = np.array(all_dat_dims_cross)\n",
    "\n",
    "dim_data_cross_ranked = all_dat_dims_cross[:,:,sorted_idx]\n",
    "dim_data_cross_ranked_avg = np.mean(dim_data_cross_ranked,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load permutations and check whether cross-decoding & difference between within & across is significant \n",
    "significance_mat_cross,significance_mat_avg_cross = [],[]\n",
    "significance_mat_diff,significance_mat_avg_diff = [],[]\n",
    "\n",
    "for test_participant in range(1,5):\n",
    "    corr_ridge_perm_avgcv_cross,corr_ridge_perm_avgcv_within,corr_ridge_perm_avgcv_diff = [],[],[]\n",
    "    for train_participant in range(1,5):\n",
    "        if test_participant!=train_participant:\n",
    "            corr_ridge_perm_cross_all = np.load(f'{res_folder}/Ridge-reg_cross_trainP{train_participant}_testP{test_participant}_permutations.npy') \n",
    "            corr_ridge_perm_within_all = np.load(f'{res_folder}/P{test_participant}_ridge-reg_within_predict-dims_permutations.npy') \n",
    "            diff_perm = corr_ridge_perm_cross_all-corr_ridge_perm_within_all\n",
    "\n",
    "            corr_ridge_perm_avgcv_cross.append(np.mean(corr_ridge_perm_cross_all,axis=0))\n",
    "            corr_ridge_perm_avgcv_within.append(np.mean(corr_ridge_perm_within_all,axis=0))\n",
    "            corr_ridge_perm_avgcv_diff.append(np.mean(diff_perm,axis=0))\n",
    "\n",
    "    # average over train participants\n",
    "    corr_ridge_perm_avg_cross = np.mean(corr_ridge_perm_avgcv_cross,axis=0)\n",
    "    corr_ridge_perm_avg_diff = np.mean(corr_ridge_perm_avgcv_diff,axis=0)\n",
    "    # get 95%ile for each timepoint and each dimension null-distribution\n",
    "    thresholds_cross = np.array([[np.percentile(corr_ridge_perm_avg_cross[:,t,d],99) for t in range(281)] for d in range(66)])\n",
    "    thresholds_diff = np.array([[np.percentile(corr_ridge_perm_avg_diff[:,t,d],99) for t in range(281)] for d in range(66)])\n",
    "    \n",
    "    # threshold defined as the max 95%ile across time and dimensions\n",
    "    threshold_cross = np.max(thresholds_cross)\n",
    "    threshold_diff = np.max(thresholds_diff)\n",
    "    \n",
    "    significance_mat_cross.append(all_dat_dims_cross[test_participant-1,:,:]>threshold_cross)\n",
    "    significance_mat_avg_cross.append(np.mean(all_dat_dims_cross[test_participant-1,:,:],axis=1)>threshold_cross)\n",
    "    \n",
    "    all_dat_dims_diff = all_dat_dims_cross-np.array(all_dat_dims)\n",
    "    significance_mat_diff.append(np.array(all_dat_dims_diff)[test_participant-1,:,:]>threshold_diff)\n",
    "    significance_mat_avg_diff.append(np.mean(all_dat_dims_diff[test_participant-1,:,:],axis=1)>threshold_diff)\n",
    "\n",
    "\n",
    "# generate one matrix that is participants x dimensions x time that tells us when stuff is significant    \n",
    "significance_mat_cross = np.array(significance_mat_cross)\n",
    "significance_mat_avg_cross = np.array(significance_mat_avg_cross)\n",
    "significance_mat_rank_cross = significance_mat_cross[:,:,sorted_idx]\n",
    "\n",
    "significance_mat_diff = np.array(significance_mat_diff)\n",
    "significance_mat_avg_diff = np.array(significance_mat_avg_diff)\n",
    "significance_mat_rank_diff = significance_mat_diff[:,:,sorted_idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE RESULTS FIGURE\n",
    "plt.close('all')\n",
    "axd = plt.figure(constrained_layout=True,figsize=(8.25, 11.75)).subplot_mosaic(\n",
    "\n",
    "    \"\"\"\n",
    "    ....\n",
    "    WXYZ\n",
    "    ....\n",
    "    CDEF\n",
    "    GHIJ\n",
    "    KLMN\n",
    "    OPQR\n",
    "    ....\n",
    "    ....\n",
    "    ....\n",
    "    \"\"\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "for p,ax in enumerate([axd['W'],axd['X'],axd['Y'],axd['Z']]):\n",
    "    # within\n",
    "    ax.plot(epochs.times*1000,np.mean(dim_data_ranked[p,:,:],axis=1),'gray',alpha=0.3,label='within')\n",
    "    sig_tp = (epochs.times*1000)[significance_mat_avg[p,:]]\n",
    "    ax.plot(sig_tp,np.repeat(0,len(sig_tp==1)),marker='.',color='gray',alpha=0.1,markersize=1)\n",
    "    \n",
    "    #cross\n",
    "    ax.plot(epochs.times*1000,np.mean(dim_data_cross_ranked[p,:,:],axis=1),'gray',label='across')\n",
    "    sig_tp = (epochs.times*1000)[significance_mat_avg_cross[p,:]]\n",
    "    ax.plot(sig_tp,np.repeat(-.007,len(sig_tp==1)),marker='.',color='gray',alpha=1,markersize=1)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xlim([epochs.times[0]*1000,epochs.times[-1]*1000])\n",
    "    ax.set_ylim([-0.01,0.15])\n",
    "    ax.legend(frameon=False,fontsize=8)\n",
    "\n",
    "    axin2 = ax.inset_axes([-100,-0.15, 1400,0.13], transform= ax.transData)\n",
    "\n",
    "    # Boxplots at timepoints of interest\n",
    "    x = epochs.times*1000\n",
    "    y = np.mean(avg_dim_data_ranked-dim_data_cross_ranked, axis=1)    \n",
    "    points_of_interest_ms = [100, 200, 300, 400, 500, 600 ]\n",
    "    points_of_interest=np.array([np.where(x==v)[0][0] for v in points_of_interest_ms])\n",
    "    \n",
    "    bp_data = np.mean([all_dat_dims_diff[p,i:i2,:] for i,i2 in zip(points_of_interest-2,points_of_interest+3)],axis=1)\n",
    "    bp = axin2.boxplot(bp_data.T, patch_artist=True,positions=points_of_interest_ms,widths=80,showfliers=False)\n",
    "    [i.set_color('grey') for i in bp['boxes']]\n",
    "    [i.set_color('red') for i in bp['medians']]\n",
    "\n",
    "    [i.set_alpha(0.6) for i in bp['boxes']]\n",
    "\n",
    "    axin2.scatter(np.repeat(points_of_interest_ms,66),all_dat_dims_diff[p,points_of_interest,:],1,'k')\n",
    "    \n",
    "    axin2.set_xticks([0,500,1000])\n",
    "    axin2.set_xticklabels([0,500,1000])\n",
    "\n",
    "    axin2.set_xlim([-100,1400])\n",
    "    axin2.set_ylim([-0.14,0.02])\n",
    "\n",
    "    # stylize axis \n",
    "    axin2.spines['top'].set_visible(False)\n",
    "    axin2.spines['right'].set_visible(False)\n",
    "    axin2.set_title('')\n",
    "    axin2.set_xlim([epochs.times[0]*1000,epochs.times[-1]*1000])\n",
    "\n",
    "    if p==0:\n",
    "        axin2.set_ylabel('Difference',fontsize=8)\n",
    "        ax.set_ylabel('Correlation', labelpad=10,fontsize=8)\n",
    "    if p>0:\n",
    "        ax.set_yticks([])\n",
    "        axin2.set_yticks([])\n",
    "    \n",
    "    ax.set_title(f'S0{p+1}')\n",
    "    axin2.set_xlabel('time (ms)')\n",
    "\n",
    "\n",
    "### B\n",
    "# add individual timeseries\n",
    "dim_ranks = [int(i) for i in np.round(np.linspace(0,65,6))]\n",
    "dim_ranks = np.arange(0,65,7)\n",
    "dim_ranks = [0,3,5,7,8,9,14,21,28,31]\n",
    "dim_ranks = [0,4,5,7,8,9,14,22,25,30]\n",
    "dim_ranks = [0,4,7,8]\n",
    "\n",
    "\n",
    "all_ax = [[axd['C'],axd['D'],axd['E'],axd['F']],\n",
    "            [axd['G'],axd['H'],axd['I'],axd['J']],\n",
    "            [axd['K'],axd['L'],axd['M'],axd['N']],\n",
    "            [axd['O'],axd['P'],axd['Q'],axd['R']]]\n",
    "for p in range(4):\n",
    "    for rank,ax in zip(dim_ranks,np.array(all_ax)[:,p]):\n",
    "        ax.plot(epochs.times*1000, epochs.times*0, 'grey', lw=1, linestyle='--')\n",
    "        ax.plot(epochs.times*1000,dim_data_ranked[p,:,rank],c=colours_ranked[rank,:],linestyle='-',lw=1,alpha=0.4,label='within')\n",
    "        ax.plot(epochs.times*1000,dim_data_cross_ranked[p,:,rank],c=colours_ranked[rank,:],lw=2,label='across')\n",
    "        \n",
    "        sig_tp = (epochs.times*1000)[significance_mat_rank_cross[p,:,rank]]\n",
    "        ax.plot(sig_tp,np.repeat(-.02,len(sig_tp==1)),marker='.',c=colours_ranked[rank,:],alpha=1,markersize=1)\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_ylim([-0.05,0.37])\n",
    "        ax.set_xlim([epochs.times[0]*1000,epochs.times[-1]*1000])\n",
    "        ax.legend(frameon=False,fontsize=8)\n",
    "\n",
    "        if p ==0:\n",
    "            label_text = f'{labels_ranked.loc[rank,0]} ({sorted_idx[rank]+1})'\n",
    "            slash_index = label_text.rfind(\"/\")\n",
    "            bracket_index = label_text.find(\"(\")\n",
    "            \n",
    "            # Insert a line break before the first \"/\"\n",
    "            if slash_index != -1:  # Check if \"/\" is found\n",
    "                label_text = f'{label_text[:slash_index+1]}\\n{label_text[slash_index+1:]}'\n",
    "            else:\n",
    "                label_text = f'{label_text[:bracket_index]}\\n{label_text[bracket_index:]}'\n",
    "            # title = ax.set_title(label_text, fontsize=text_size_small, y=0.9)\n",
    "            ax.set_ylabel(f'{label_text}', labelpad=10,fontsize=8)\n",
    "        if p>0:\n",
    "            ax.set_yticks([])\n",
    "        \n",
    "        if rank == dim_ranks[-1]:\n",
    "            ax.set_xlabel('time (ms)')\n",
    "        else:\n",
    "            ax.set_xticklabels('')\n",
    "        if rank ==dim_ranks[0]:\n",
    "            ax.set_title(f'S0{p+1}', y=0.9)\n",
    "\n",
    "# add A and B labels\n",
    "fig.text(0.01,0.92,'A',fontsize=text_size_big*2)\n",
    "fig.text(0.01,0.63,'B',fontsize=text_size_big*2)\n",
    "\n",
    "\n",
    "fig.savefig(f'{bids_dir}/derivatives/meg_paper/figures/Figure3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplementary with table with differences and stats for diff timewindows\n",
    "from scipy.stats import ttest_rel\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "plt.close('all')\n",
    "axd = plt.figure(constrained_layout=True,figsize=(8.25, 11.75)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    HA.\n",
    "    IB.\n",
    "    JC.\n",
    "    KD.\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    \"\"\")\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "\n",
    "for p,ax in enumerate([axd['H'],axd['I'],axd['J'],axd['K']]):\n",
    "    # Boxplots at timepoints of interest\n",
    "    x = epochs.times*1000\n",
    "    y = np.mean(avg_dim_data_ranked-dim_data_cross_ranked, axis=1)    \n",
    "    points_of_interest_ms = [100, 200, 300, 400, 500, 600 ]\n",
    "    points_of_interest=np.array([np.where(x==v)[0][0] for v in points_of_interest_ms])\n",
    "    \n",
    "    bp_data = np.mean([all_dat_dims_diff[p,i:i2,:] for i,i2 in zip(points_of_interest-2,points_of_interest+3)],axis=1)\n",
    "    bp = ax.boxplot(bp_data.T, patch_artist=True,positions=points_of_interest_ms,widths=80,showfliers=False)\n",
    "    [i.set_color('grey') for i in bp['boxes']]\n",
    "    [i.set_color('red') for i in bp['medians']]\n",
    "\n",
    "    [i.set_alpha(0.6) for i in bp['boxes']]\n",
    "\n",
    "    ax.scatter(np.repeat(points_of_interest_ms,66),all_dat_dims_diff[p,points_of_interest,:],1,'k')\n",
    "    \n",
    "    ax.set_xticks([0,500,1000])\n",
    "    ax.set_xticklabels([0,500,1000])\n",
    "\n",
    "    ax.set_xlim([-100,1400])\n",
    "    ax.set_ylim([-0.14,0.02])\n",
    "\n",
    "    # stylize axis \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_title('')\n",
    "    ax.set_xlim([epochs.times[0]*1000,epochs.times[-1]*1000])\n",
    "\n",
    "    ax.set_ylabel('Difference')\n",
    "\n",
    "    \n",
    "    ax.set_title(f'S0{p+1}')\n",
    "    ax.set_xlabel('time (ms)')\n",
    "    \n",
    "    \n",
    "for p,ax in enumerate([axd['A'],axd['B'],axd['C'],axd['D']]):\n",
    "    \n",
    "    bp_data = np.mean([all_dat_dims_diff[p,i:i2,:] for i,i2 in zip(points_of_interest-2,points_of_interest+3)],axis=1)\n",
    "    n_timepoints = bp_data.shape[0]\n",
    "    p_values,mean_differences = [],[]\n",
    "    \n",
    "    # Calculate p-values for paired comparisons between time points\n",
    "    for i in range(n_timepoints):\n",
    "        for j in range(i + 1, n_timepoints):\n",
    "            stat, p_val = ttest_rel(bp_data[i], bp_data[j])  # Using paired t-test\n",
    "            p_values.append(p_val)\n",
    "            mean_diff = np.mean(bp_data[i]) - np.mean(bp_data[j])\n",
    "            mean_differences.append(mean_diff)\n",
    "    rejections, corrected_p_values = multipletests(p_values, alpha=0.01,method='bonferroni')[:2]\n",
    "\n",
    "    # Table\n",
    "    table_data = np.full((n_timepoints, n_timepoints), '', dtype=object)\n",
    "    for idx, (i, j) in enumerate(((i, j) for i in range(n_timepoints) for j in range(n_timepoints) if i < j)):\n",
    "        formatted = f\"{mean_differences[idx]:.3f}\"\n",
    "        if formatted.startswith('0'):\n",
    "            formatted = formatted[1:] \n",
    "        if formatted.startswith('-0'):\n",
    "            formatted =  formatted.replace('-0', '-')\n",
    "        if rejections[idx]:\n",
    "            table_data[i, j] = f\"{formatted}*\"\n",
    "        else:\n",
    "            table_data[i, j] = f\"{formatted}\"\n",
    "        \n",
    "    colors = np.full((n_timepoints, n_timepoints), 'white', dtype=object)\n",
    "    for idx, (i, j) in enumerate(((i, j) for i in range(n_timepoints) for j in range(n_timepoints) if i < j)):\n",
    "        if rejections[idx]:\n",
    "            colors[i, j] = 'green'  # Reject null\n",
    "            colors[j, i] = 'white' \n",
    "        else:\n",
    "            colors[i, j] = 'red'    # Do not reject null\n",
    "            colors[j, i] = 'white' \n",
    "\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Create the table\n",
    "    table = ax.table(cellText=table_data, cellColours=colors, colLabels=[f'{i}ms' for i in points_of_interest_ms],\n",
    "                    rowLabels=[f' {i}ms ' for i in points_of_interest_ms], cellLoc='center', loc='center')\n",
    "\n",
    "    # # Set lower triangle cells and first column cells to be empty \n",
    "    for i in range(n_timepoints):\n",
    "        for j in range(n_timepoints):\n",
    "            if j < i:  # Lower triangle\n",
    "                table[i + 1, j + 1].set_text_props(text='')\n",
    "            if j == 0:  # First column\n",
    "                table[i + 1, j].set_text_props(text='')\n",
    "\n",
    "    # Adjust font size and table properties\n",
    "    for key, cell in table.get_celld().items():\n",
    "        cell.set_fontsize(12)  # Adjust font size as needed\n",
    "        cell.set_edgecolor('k')  # Optional: set edge color for clarity\n",
    "\n",
    "    # Adjust the axes limits to fit the table better\n",
    "    ax.set_xlim([-100,1400])\n",
    "    ax.set_ylim([-0.14,0.02])\n",
    "\n",
    "fig.savefig(f'{bids_dir}/derivatives/meg_paper/figures/Supplementary_timewindows_stats.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplementary figure showing all dimension timecourses\n",
    "plt.close('all')\n",
    "fig,axs = plt.subplots(figsize=(8.25, 11.75),num=2,ncols=6,nrows=11,sharex=True,sharey=True)\n",
    "text_size_small = 7\n",
    "\n",
    "axs=axs.flatten()\n",
    "\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.plot(epochs.times*1000,epochs.times*0,'grey',linestyle='--')\n",
    "    for p in range(4):\n",
    "        ax.plot(epochs.times*1000,dim_data_cross_ranked[p,:,i],c=colours_ranked[i,:],alpha=0.3,lw=1)\n",
    "        sig_tp = (epochs.times*1000)[significance_mat_rank_cross[p,:,i]]\n",
    "        ax.plot(sig_tp,np.repeat(-.02-(p*1/50),len(sig_tp==1)),'k.',mfc=colours_ranked[i,:],mec=colours_ranked[i,:],alpha=0.3,markersize=.8)\n",
    "\n",
    "    ax.plot(epochs.times*1000,dim_data_cross_ranked_avg[:,i],c=colours_ranked[i,:],lw=2)\n",
    " \n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_ylim([-0.11,0.3])\n",
    "\n",
    "    ax.set_title(f'{labels_ranked.loc[i,0]}\\n({sorted_idx[i]+1})',c='k',fontsize=text_size_small)\n",
    "    ax.set_xlim([epochs.times[0]*1000,epochs.times[-1]*1000])\n",
    "\n",
    "\n",
    "fig.supylabel('Correlation: true vs predicted label')\n",
    "fig.supxlabel('time (ms)')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(f'{bids_dir}/derivatives/meg_paper/figures/Supplementary_cross.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
